{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic_df = pd.read_csv('.../titanic_train.csv')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n ## Train data information ## \\n')\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 891 Rows\n",
    "# 12 Columns\n",
    "# 2 float64 columns\n",
    "# 5 int64 columns\n",
    "# 5 objct columns\n",
    "# And so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "titanic_df['Cabin'].fillna('N', inplace=True)\n",
    "titanic_df['Embarked'].fillna('N', inplace=True)\n",
    "print('Number of Null is', titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution of Sex value: \\n', titanic_df['Sex'].value_counts())\n",
    "print('Distribution of Cabin value: \\n', titanic_df['Cabin'].value_counts())\n",
    "print('Distribution of Embarked value: \\n', titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In terms of Cabin data, there are some values having a multiple expression\n",
    "# Assumption: the first character means the level of the room (cabin) and it is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "print(titanic_df['Cabin'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby(['Sex', 'Survived'])['Survived'].count()\n",
    "# Survived 0 is died and 1 is survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Sex', y='Survived', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(age):\n",
    "    cat=''\n",
    "    if age <=-1: cat='Unknown'\n",
    "    elif age <=5: cat='Baby'\n",
    "    elif age <=12: cat='Child'\n",
    "    elif age <=18: cat='Teenager'\n",
    "    elif age <=25: cat='Student'\n",
    "    elif age <=35: cat='Young Adult'\n",
    "    elif age <=60: cat='Adult'\n",
    "    else : cat='Elderly'\n",
    "\n",
    "    return cat\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# This is to make an order in the graph\n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Eldery']\n",
    "\n",
    "# \n",
    "# \n",
    "titanic_df['Age_cat']=titanic_df['Age'].apply(lambda x : get_category(x))\n",
    "sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order=group_names)\n",
    "titanic_df.drop('Age_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to convert the string characteristics to the numerical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Null\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Eliminate Unnecessary features\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Execute label encoding\n",
    "def format_features(df):\n",
    "    df['Cabin']=df['Cabin'].str[:1]\n",
    "    features=['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le=le.fit(df[feature])\n",
    "        df[feature]=le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# Call the previous preprocessing function\n",
    "def transform_features(df):\n",
    "    df=fillna(df)\n",
    "    df=drop_features(df)\n",
    "    df=format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the raw data set and export feature data set and label data set\n",
    "titanic_df = pd.read_csv('.../titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived',axis=1)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Test data size is 20%\n",
    "# random_state=11 is to make the same result in every examples, so you could delete this part when you are doing your own study\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn provides three different Decision trees: DescisionTreeClassifier, RandomForesetClassifier, and LogisticRegression\n",
    "# solver='liblinear' is an optimazation algorithm in LogisticRegression and shows a good performance in binary sorted (relatively small) data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('Accuracy of DecisionTreeClassifier: {0:.4f}'.format(accuracy_score(y_test,dt_pred)))\n",
    "\n",
    "# RandomForestClassifier\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('Accuracy of RandomForestClassifier: {0:.4f}'.format(accuracy_score(y_test,rf_pred)))\n",
    "\n",
    "# LogisticRegession\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('Accuracy of LogisticRegression: {0:.4f}'.format(accuracy_score(y_test,lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even if we didnt do any of optimization work and there is no sufficient data size, lr_clf showed better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    # Create KFold having 5 folds \n",
    "    kfold=KFold(n_splits=folds)\n",
    "    scores=[]\n",
    "\n",
    "    # Conduct KFold cross validation\n",
    "    for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # In X_titanic_df data set, create indexes for each of test and train data\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        # Calculate a classfier's accuracy of train and prediction\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions=clf.predict(X_test)\n",
    "        accuracy=accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print('Cross validation {0} accuracy: {1:.4f}'.format(iter_count, accuracy))\n",
    "\n",
    "    mean_score=np.mean(scores)\n",
    "    print(\"Average accuracy: {0:.4f}\".format(mean_score))\n",
    "\n",
    "exec_kfold(dt_clf, folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print('Accuracy of Cross validation {0}: {1:.4f}'.format(iter_count, accuracy))\n",
    "\n",
    "print('Average accuracy: {0:.4f}'.format(np.mean(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', cv=5)\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearchCVs the optimized hyper parameter:', grid_dclf.best_params_)\n",
    "print('GridSearchCVs the highest accuracy: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "# Conduct the prediction and evaluation with the estimator studied by GridSearchCV's the optimized hyper parameter\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print('DecisionTreeClassifier accuracy in the test data set: {0:.4f}'.format(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
