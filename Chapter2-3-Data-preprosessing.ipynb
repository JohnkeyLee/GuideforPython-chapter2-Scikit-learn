{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding is to convert a category feature to a code-type number\n",
    "# Such \"01\", \"02\" are the same as string type, which requries coverting process\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', 'Fridge', 'Microwave', 'PC', 'Fan', 'Fan', 'Blender', 'Blender']\n",
    "\n",
    "# After create 'LabelEncoder' as an object, conduct label encoding with 'fit()' and 'transform()'\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "print('Encoding converted values:', labels)\n",
    "print('Encoding Class:', encoder.classes_)\n",
    "print('Decoded original value:', encoder.inverse_transform([4,5,2,0,1,1,3,3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding is to avoid a happening lowering the accuracy of prediction \n",
    "# This is the converting process to Sparse matrix\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', 'Fridge', 'Microwave', 'PC', 'Fan', 'Fan', 'Blender', 'Blender']\n",
    "\n",
    "# Convert to 2D ndarray\n",
    "items = np.array(items).reshape(-1,1)\n",
    "\n",
    "# Apply 'OneHotEncoder'\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(items)\n",
    "oh_labels = oh_encoder.transform(items)\n",
    "\n",
    "# Since a result converted by using OneHotEncoder Sparse matrix, Need to covert it by using 'toarray()' to Dense matrix\n",
    "print('OneHotEncoder data:')\n",
    "print('\\n', oh_labels.toarray())\n",
    "print('\\n Data dimension of OneHotEncoder:', oh_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item':['TV', 'Fridge', 'Microwave', 'PC', 'Fan', 'Fan', 'Blender', 'Blender']})\n",
    "\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling: Standardization and Normalization\n",
    "# Standardization has each mean value is 0 and variation is 1 (Gaussian normal distribution)\n",
    "# In Standardization, if a feature x's ith data is x_i-new = (x_i-mean(X))/stdev(x)\n",
    "# what if Feature A ranges 0 to 100 ft while Feature B has $0 to $100,000,000, the normalization coverts them into 0 to 1 \n",
    "# x_i-new=(x_i-min(x))/(max(x)-minx(x))\n",
    "# However, the Normalizer in Scikitlearn is x_i-new=x_i/(SQRT(x_i^2+y_i^2+z_i^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load iris data set and convert it to DateFrame\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "print('Average value of feastures')\n",
    "print(iris_df.mean())\n",
    "print('\\nVariance of features')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Generate StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "# Convert data set with StandardScaler and call fit() and transform()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# Data set after converted the scale when you did transform(), is returned as Numpy ndarray and return it as DataFrame\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "print('Average value of feastures')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nVariance of features')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Generate MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "# Convert data set with MinMaxScaler and call fit() and transform()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# Data set after converted the scale when you did transform(), is returned as Numpy ndarray and return it as DataFrame\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "print('Min value of feastures')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nMax of features')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'fit()' is to set a reference information such as the max/min of data set\n",
    "# 'transform()' covnert it based on the reference information\n",
    "# 'fit_tranform()' has a function of these two combination\n",
    "\n",
    "# It is important once you have done fit() and transform() on your a training data set, you should not do fit() on you a testing data set\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Generate data set, Traing data 0 to 10 and Testing data 0 to 5\n",
    "# fit() and transform() of Scaler class are only possible from 2darray, so that covert the dimension with reshape(-1,1)\n",
    "\n",
    "train_array = np.arange(0,11).reshape(-1,1)\n",
    "test_array = np.arange(0,6).reshape(-1,1)\n",
    "\n",
    "# If you don't specify feature_range's parameter value in MinMaxScaler, it coverts value ranging 0 to 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# If you do fit(), data in train_array of Min and Max are 0 and 10 each\n",
    "scaler.fit(train_array)\n",
    "\n",
    "# Convert train_array to 1/10 scale (Original data 10 -> 1)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('Original tranin_array data:', np.round(train_array.reshape(-1),2))\n",
    "print('Scaled tranin_array data:', np.round(train_scaled.reshape(-1),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In MinMaxScaler, when you do fit() on test_array, the original data set the Min and Max as 0 and 5 for each\n",
    "scaler.fit(test_array)\n",
    "\n",
    "# Convert test_array to 1/5 scale (Original data 5 -> 1)\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "# Return converted scale of test_array\n",
    "print('Original test_array data:', np.round(test_array.reshape(-1),2))\n",
    "print('Scaled test_array data:', np.round(test_scaled.reshape(-1),2))\n",
    "\n",
    "# In this case, we can see the scale is differnt to the previous one and it is not possible to use for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('Original tranin_array data:', np.round(train_array.reshape(-1),2))\n",
    "print('Scaled tranin_array data:', np.round(train_scaled.reshape(-1),2))\n",
    "\n",
    "# When you do scaling conversion on test_array, you HAVE TO not calling fit(), butt using only transform()\n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('\\nOriginal tranin_array data:', np.round(test_array.reshape(-1),2))\n",
    "print('Scaled tranin_array data:', np.round(test_scaled.reshape(-1),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
